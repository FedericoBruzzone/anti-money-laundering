{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f364894d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    GITHUB_TOKEN = \"\"\n",
    "    !rm -rf anti_money_laundering\n",
    "    !git clone https://{GITHUB_TOKEN}@github.com/FedericoBruzzone/anti_money_laundering.git\n",
    "    !mv anti_money_laundering/* \n",
    "    !rm -rf anti_money_laundering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42222b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# load_dotenv()\n",
    "\n",
    "# os.environ['KAGGLE_USERNAME'] = os.getenv(\"KAGGLE_USER\")\n",
    "# os.environ['KAGGLE_KEY'] = os.getenv('KAGGLE_KEY')\n",
    "# !cd datasets\n",
    "# !kaggle datasets download -d --unzip {os.getenv('KAGGLE_DATASET_LINK')}\n",
    "# !cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642e793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from src.utils.kaggle_config            import setup_kaggle\n",
    "from src.utils.kaggle_config            import download_dataset\n",
    "\n",
    "from src.utils.datasets_handler         import (get_train_and_test,\n",
    "                                                get_X_and_Y,\n",
    "                                                print_dataset,\n",
    "                                                label_encoder,\n",
    "                                                split_timestamp)\n",
    "from src.utils.performance_measures     import calculate_performances\n",
    "from src.utils.dataset_sampling_methods import (oversampling,\n",
    "                                                undersampling,\n",
    "                                                bootstrap_sampling)\n",
    "\n",
    "from src.utils.print_utils              import (printLBlue, printGreen)\n",
    "\n",
    "from src.decision_tree.decision_tree    import CustomDecisionTree\n",
    "from src.decision_tree.ID3              import DecisionTreeID3\n",
    "from src.decision_tree.C45              import DecisionTreeC45\n",
    "from src.decision_tree.entropy_type     import EntropyType\n",
    "from src.decision_tree.criterion_type   import CriterionType\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from pyspark import TaskContext\n",
    "import pandas as pd\n",
    "\n",
    "VERBOSE = int(os.getenv('VERBOSE'))\n",
    "VIEW = os.getenv('VIEW')\n",
    "\n",
    "setup_kaggle()\n",
    "print(\"Downloading dataset...\") \n",
    "download_dataset(\"iammustafatz/diabetes-prediction-dataset\")\n",
    "download_dataset(\"ealtman2019/ibm-transactions-for-anti-money-laundering-aml\")\n",
    "print(\"Done.\")\n",
    "\n",
    "hi_small_trans = \"HI-Small_Trans.csv\"\n",
    "diabetes = \"diabetes_prediction_dataset.csv\"\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8445ecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trees(partition_elements, verbose=False):\n",
    "    list_series = []\n",
    "    for element in partition_elements:\n",
    "        series_tmp = pd.Series(element.asDict())\n",
    "        list_series.append(series_tmp)\n",
    "\n",
    "    part_df = pd.DataFrame(list_series, columns=COLUMNS_NAME)\n",
    "    X_train, y_train = get_X_and_Y(part_df, verbose=VERBOSE)\n",
    "    X_train, _ = label_encoder(X_train, ['Timestamp', 'Account', 'Account.1', 'Receiving Currency', 'Payment Currency', 'Payment Format'])\n",
    "\n",
    "    decision_tree: DecisionTreeID3 = DecisionTreeID3(max_depth=8,\n",
    "                                                     num_thresholds_numerical_attr=2,\n",
    "                                                     VERBOSE=False)\n",
    "    decision_tree.fit(X_train, y_train)\n",
    "\n",
    "    if verbose:\n",
    "        ctx = TaskContext()\n",
    "        decision_tree.create_dot_files(filename=\"tree\" + str(ctx.partitionId()),\n",
    "                                       generate_png=True,\n",
    "                                       view=\"default-viewer\")\n",
    "    yield decision_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2f5e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_trees(new_line):\n",
    "    def wrap(tree):\n",
    "        prediction = tree.predict(new_line)\n",
    "        return prediction\n",
    "    return wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7321609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_trees_all(X_test):\n",
    "    def wrap(tree):\n",
    "        predictions = tree.predict_test_no_gen(X_test)\n",
    "        return predictions\n",
    "    return wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37bd970",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERBOSE = int(os.getenv('VERBOSE'))\n",
    "VIEW = os.getenv('VIEW')\n",
    "name = \"AntiMoneyLaundering\"\n",
    "\n",
    "spark = get_spark_session(name, VERBOSE)\n",
    "\n",
    "setup_kaggle()\n",
    "print(\"---------------------- Downloading dataset ----------------------\")\n",
    "download_dataset(\"uciml/iris\")\n",
    "download_dataset(\"ealtman2019/ibm-transactions-for-anti-money-laundering-aml\")\n",
    "print(\"---------------------- End downloading dataset ----------------------\")\n",
    "\n",
    "df_train, df_test = get_train_and_test(hi_small_trans, verbose=VERBOSE)\n",
    "df_train = bootstrap_sampling(df_train)\n",
    "# df_train = oversampling(df_train, VERBOSE=False)\n",
    "\n",
    "COLUMNS_NAME: list = df_train.columns.tolist()\n",
    "X_train, y_train = get_X_and_Y(df_train, verbose=VERBOSE)\n",
    "X_test, y_test = get_X_and_Y(df_test, verbose=VERBOSE)\n",
    "\n",
    "# X_train, _ = label_encoder(X_train, ['Timestamp', 'Account', 'Account.1', 'Receiving Currency', 'Payment Currency', 'Payment Format'])\n",
    "X_test, _ = label_encoder(X_test, ['Timestamp', 'Account', 'Account.1', 'Receiving Currency', 'Payment Currency', 'Payment Format'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7329d25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_column_value_pairs(row):\n",
    "    return [(i, row[i]) for i in range(len(row))]\n",
    "\n",
    "def count_values(a, b):\n",
    "    return a + b\n",
    "\n",
    "predictions = rdd.mapPartitions(create_trees, False) \\\n",
    "                 .map(predict_trees_all(X_test)) \\\n",
    "                 .flatMap(map_to_column_value_pairs) \\\n",
    "                 .map(lambda x: (x, 1)) \\\n",
    "                 .reduceByKey(count_values) \\\n",
    "                 .map(lambda x: (x[0][0], [(x[0][1], x[1])])) \\\n",
    "                 .reduceByKey(count_values) \\\n",
    "                 .map(lambda x: (x[0], max(x[1], key=lambda item: item[1]))) \\\n",
    "                 .map(lambda x: x[1][0]) \\\n",
    "                 .collect()\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eca05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_performances(predictions, y_test, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38a9c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
